{\rtf1\ansi\ansicpg1252\cocoartf1671\cocoasubrtf200
{\fonttbl\f0\fmodern\fcharset0 CourierNewPSMT;\f1\fmodern\fcharset0 CourierNewPS-BoldMT;\f2\fswiss\fcharset0 Helvetica;
}
{\colortbl;\red255\green255\blue255;\red0\green0\blue0;}
{\*\expandedcolortbl;;\csgray\c0\c0;}
\paperw11900\paperh16840\margl1440\margr1440\vieww22080\viewh12540\viewkind0
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0

\f0\fs28 \cf0 How to run this program \
\

\f1\b Required Installation
\f0\b0 \
The program used a few auxiliary libraries. These auxiliary libraries include \
NLTK, numpy, pandas, csv. Please pip/conda install these packages before running the program \
\
\

\f1\b Training Process
\f0\b0 \
\
To train this program, you need to include 3 parameters:\
1) examples - the training example file. \
2) hypothesisOut - the file to write the model to - This is a name that you can make up \
3) learning-type - which learning algorithm to train. It is either \'93dt\'94 (DecisionTree) or \'93ada\'94 (Adaboost)\
\

\f1\b Usage
\f0\b0 \
python train.py <examples> <hypothesisOut> <learning-type>\
\
Training files are available in the processed_data directory. Under this directory, there is a train.txt and test.txt\
1) train.txt - For training\
2) test.txt - For validation, checking what the accuracy the classifier achieved in this test.txt \
\

\f1\b Warning 
\f0\b0 \
The adaboost takes a while to train as it is creating a decision stump each time. To loop through 10 stumps, \
it may take up to a minute. \
\

\f1\b Information\

\f0\b0 For decision tree, when the training is completed, it will generate a <hypothesisOut>.py file. It is creating a python if statement classifiers.\
\

\f1\b Example Run:
\f0\b0 \
\
\ul Training using Adaboost \ulnone \
python train.py processed_data/train.txt adaboostclassifier.txt ada\
\
\ul Training using Decision Tree\ulnone \
python train.py processed_data/train.txt decisiontreeClassifier.py dt\
\

\f1\b Prediction
\f0\b0  \
\
To train this program, you need to include 2 parameters:\
1) hypothesis - the best classifier generated by decision tree or adaboost \
2) file - the test file \
\
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural\partightenfactor0
\cf0 \cb2 \CocoaLigature0 The prediction will print out whether it predicted it as english or dutch in the console \cb1 \CocoaLigature1 \
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0
\cf0 \

\f1\b Usage
\f0\b0 \
python predict.py <hypothesis> <file>\
\
\ul Predicting Example Run: \ulnone \
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural\partightenfactor0
\cf0 \cb2 \CocoaLigature0 python predict.py dt processed_data/test1_prof.dat\
\
\

\f2 \cb1 \CocoaLigature1 \
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0
\cf0 \
\
\
\
\
\
}